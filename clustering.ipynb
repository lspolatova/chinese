{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f7f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('content/resnet50.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935f5588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 70, 70, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 32, 32, 64)   9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 32, 32, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 15, 15, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 15, 15, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 15, 15, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 15, 15, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 15, 15, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 15, 15, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 15, 15, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 15, 15, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 15, 15, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 15, 15, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 15, 15, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 15, 15, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 15, 15, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 15, 15, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 15, 15, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 15, 15, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 15, 15, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 15, 15, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 15, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 15, 15, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 15, 15, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 15, 15, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 15, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 15, 15, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 15, 15, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 15, 15, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 15, 15, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 15, 15, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 15, 15, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 15, 15, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 15, 15, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 15, 15, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 15, 15, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 8, 8, 128)    32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 8, 8, 512)    131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 8, 8, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 512)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 512)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 8, 8, 128)    65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 8, 8, 128)    147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 8, 8, 512)    66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 8, 8, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 4, 4, 256)    131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 4, 4, 1024)   525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 4, 4, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 4, 4, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 4, 4, 1024)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 4, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 4, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 4, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 4, 4, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 4, 4, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 4, 4, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 4, 4, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 4, 4, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 4, 4, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 4, 4, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 4, 4, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 4, 4, 256)    262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 4, 4, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 4, 4, 1024)   263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 4, 4, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 2, 2, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 2, 2, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 2, 2, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "model= Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "009e4a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_to_fonts = 'font'\n",
    "filelist = []\n",
    "for root, dirs, files in os.walk(path_to_fonts): \n",
    "    for file in files: \n",
    "        filelist.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8a73ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = filelist[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4115f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "path_to_fonts = 'img'\n",
    "X_data = []\n",
    "Y_data=[]\n",
    "#fontlist=[]\n",
    "for root, dirs, files in os.walk(path_to_fonts): \n",
    "    for file in files: \n",
    "        for font in filelist:\n",
    "            if(font in file and '30' in file):\n",
    "                X_data.append(np.asarray(Image.open(os.path.join(root,file))).astype('int8'))\n",
    "                Y_data.append(os.path.join(root,file)[4:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcd5cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6b0a7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'亟'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cac79f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(X_data[100])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b7ee777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8184, 2048)\n"
     ]
    }
   ],
   "source": [
    "result_vector_embedding = model(X_data)\n",
    "\n",
    "print(np.shape(result_vector_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52d1ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, Lambda, BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b44e146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 1000\n",
    "batch_size = 44 \n",
    " \n",
    "def dropout_and_batch(x):\n",
    "  return Dropout(0.3)(BatchNormalization()(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3448efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#энкодер\n",
    "input_img = Input((2048))\n",
    "x = Dense(256, activation='relu')(input_img)\n",
    "x = dropout_and_batch(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = dropout_and_batch(x)\n",
    "#Вектор z_mean – это МО, а вектор z_log_var – логарифм дисперсий  \n",
    "z_mean = Dense(hidden_dim)(x)\n",
    "z_log_var = Dense(hidden_dim)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76e2e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiser(args):\n",
    "  global z_mean, z_log_var\n",
    "  z_mean, z_log_var = args\n",
    "  N = K.random_normal(shape=(batch_size, hidden_dim), mean=0., stddev=1.0)\n",
    "  return K.exp(z_log_var / 2) * N + z_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ed3ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Lambda(noiser, output_shape=(hidden_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad187b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dec = Input(shape=(hidden_dim,))\n",
    "d = Dense(128, activation='relu')(input_dec)\n",
    "d = dropout_and_batch(d)\n",
    "d = Dense(256, activation='relu')(input_dec)\n",
    "d = dropout_and_batch(d)\n",
    "decoded = Dense(2048, activation='sigmoid')(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d08ac7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_img, h, name='encoder')\n",
    "decoder = Model(input_dec, decoded, name='decoder')\n",
    "vae = Model(input_img, decoder(encoder(input_img)), name=\"vae\")\n",
    "z_meaner = Model(input_img, z_mean, name='Enc_z_mean')\n",
    "z_lvarer = Model(input_img, z_log_var, name='Enc_z_log_var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "585cf370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x, y):\n",
    "  x = K.reshape(x, shape=(batch_size, 2048))\n",
    "  y = K.reshape(y, shape=(batch_size, 2048))\n",
    "  # первый критерий – разница между входным и выходным сигналами\n",
    "  loss = abs(2048*binary_crossentropy(x, y))\n",
    "  #вычисление второго критерия – расстояния Кульбака-Лейблера по тензорам z_mean и z_log_var.  \n",
    "  kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "  return (loss + kl_loss)/2/2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31a2dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80d16085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.1262\n",
      "Epoch 2/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0685\n",
      "Epoch 3/150\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0579\n",
      "Epoch 4/150\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0515\n",
      "Epoch 5/150\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0456\n",
      "Epoch 6/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0410\n",
      "Epoch 7/150\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0372\n",
      "Epoch 8/150\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0342\n",
      "Epoch 9/150\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0318\n",
      "Epoch 10/150\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0296\n",
      "Epoch 11/150\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0273\n",
      "Epoch 12/150\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0252\n",
      "Epoch 13/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0233\n",
      "Epoch 14/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0218\n",
      "Epoch 15/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0203\n",
      "Epoch 16/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0190\n",
      "Epoch 17/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0178\n",
      "Epoch 18/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0166\n",
      "Epoch 19/150\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0156\n",
      "Epoch 20/150\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0149\n",
      "Epoch 21/150\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0143\n",
      "Epoch 22/150\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0133\n",
      "Epoch 23/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0128\n",
      "Epoch 24/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0121\n",
      "Epoch 25/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0115\n",
      "Epoch 26/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0110\n",
      "Epoch 27/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0107\n",
      "Epoch 28/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0102\n",
      "Epoch 29/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0099\n",
      "Epoch 30/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0097\n",
      "Epoch 31/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0094\n",
      "Epoch 32/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0094\n",
      "Epoch 33/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0088\n",
      "Epoch 34/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0086\n",
      "Epoch 35/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0084\n",
      "Epoch 36/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0084\n",
      "Epoch 37/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0081\n",
      "Epoch 38/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0081\n",
      "Epoch 39/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0079\n",
      "Epoch 40/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0079\n",
      "Epoch 41/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0076\n",
      "Epoch 42/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0078\n",
      "Epoch 43/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0076\n",
      "Epoch 44/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0076\n",
      "Epoch 45/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0076\n",
      "Epoch 46/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0073\n",
      "Epoch 47/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0072\n",
      "Epoch 48/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0073\n",
      "Epoch 49/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0074\n",
      "Epoch 50/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0074\n",
      "Epoch 51/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0071\n",
      "Epoch 52/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0071\n",
      "Epoch 53/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0071\n",
      "Epoch 54/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0071\n",
      "Epoch 55/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0071\n",
      "Epoch 56/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0071\n",
      "Epoch 57/150\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0069\n",
      "Epoch 58/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0070\n",
      "Epoch 59/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0068\n",
      "Epoch 60/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0069\n",
      "Epoch 61/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0068\n",
      "Epoch 62/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0069\n",
      "Epoch 63/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0066\n",
      "Epoch 64/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0068\n",
      "Epoch 65/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0068\n",
      "Epoch 66/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0066\n",
      "Epoch 67/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0066\n",
      "Epoch 68/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0067\n",
      "Epoch 69/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0066\n",
      "Epoch 70/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0066\n",
      "Epoch 71/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0065\n",
      "Epoch 72/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0065\n",
      "Epoch 73/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0064\n",
      "Epoch 74/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0065\n",
      "Epoch 75/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0063\n",
      "Epoch 76/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0064\n",
      "Epoch 77/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0064\n",
      "Epoch 78/150\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0062\n",
      "Epoch 79/150\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0063\n",
      "Epoch 80/150\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0062\n",
      "Epoch 81/150\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0063\n",
      "Epoch 82/150\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0065\n",
      "Epoch 83/150\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0062\n",
      "Epoch 84/150\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0062\n",
      "Epoch 85/150\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0062\n",
      "Epoch 86/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0062\n",
      "Epoch 87/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0062\n",
      "Epoch 88/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0061\n",
      "Epoch 89/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0061\n",
      "Epoch 90/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0061\n",
      "Epoch 91/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0060\n",
      "Epoch 92/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0063\n",
      "Epoch 93/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0061\n",
      "Epoch 94/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0061\n",
      "Epoch 95/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0060\n",
      "Epoch 96/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0061\n",
      "Epoch 97/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0060\n",
      "Epoch 98/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0062\n",
      "Epoch 99/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0061\n",
      "Epoch 100/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0061\n",
      "Epoch 101/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0060\n",
      "Epoch 102/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0060\n",
      "Epoch 103/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0061\n",
      "Epoch 104/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0060\n",
      "Epoch 105/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0060\n",
      "Epoch 106/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0060\n",
      "Epoch 107/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0059\n",
      "Epoch 108/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0059\n",
      "Epoch 109/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0057\n",
      "Epoch 110/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0059\n",
      "Epoch 111/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0060\n",
      "Epoch 112/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0058\n",
      "Epoch 113/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0058\n",
      "Epoch 114/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0059\n",
      "Epoch 115/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0059\n",
      "Epoch 116/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0058\n",
      "Epoch 117/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0056\n",
      "Epoch 118/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0058\n",
      "Epoch 119/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0058\n",
      "Epoch 120/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0058\n",
      "Epoch 121/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0058\n",
      "Epoch 122/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0057\n",
      "Epoch 123/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0057\n",
      "Epoch 124/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0058\n",
      "Epoch 125/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0058\n",
      "Epoch 126/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0058\n",
      "Epoch 127/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0057\n",
      "Epoch 128/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0057\n",
      "Epoch 129/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0056\n",
      "Epoch 130/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0057\n",
      "Epoch 131/150\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0059\n",
      "Epoch 132/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0056\n",
      "Epoch 133/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0056\n",
      "Epoch 134/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0057\n",
      "Epoch 135/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0055\n",
      "Epoch 136/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0056\n",
      "Epoch 137/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0057\n",
      "Epoch 138/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0056\n",
      "Epoch 139/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0056\n",
      "Epoch 140/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0057\n",
      "Epoch 141/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0056\n",
      "Epoch 142/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0056\n",
      "Epoch 143/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0056\n",
      "Epoch 144/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0056\n",
      "Epoch 145/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0057\n",
      "Epoch 146/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0055\n",
      "Epoch 147/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0055\n",
      "Epoch 148/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0055\n",
      "Epoch 149/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0055\n",
      "Epoch 150/150\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1282f6ac580>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(result_vector_embedding, result_vector_embedding, epochs=150, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfb8b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encode = z_meaner.predict(result_vector_embedding, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10328f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "p_field = TSNE().fit_transform(X_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4000e04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1283cb2f460>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#скрытый слой\n",
    "plt.scatter(p_field[:, 0], p_field[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e332e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=10).fit(X_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "499c9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(lst, el):\n",
    "    return [i for i in range(len(lst)) if lst[i] == el]\n",
    "indeces = get_indices(kmeans.labels_, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52420874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "α\n",
      "γ\n",
      "δ\n",
      "丁\n",
      "丈\n",
      "丸\n",
      "久\n",
      "亏\n",
      "互\n",
      "亓\n",
      "井\n",
      "亨\n",
      "亩\n",
      "亹\n",
      "亿\n",
      "仃\n",
      "从\n",
      "仚\n",
      "仞\n",
      "仪\n",
      "仰\n",
      "仲\n",
      "企\n",
      "伢\n",
      "伥\n",
      "伦\n",
      "估\n",
      "伴\n",
      "位\n",
      "住\n",
      "佤\n",
      "佫\n",
      "佴\n",
      "併\n",
      "侂\n",
      "依\n",
      "俉\n",
      "俗\n",
      "俚\n",
      "俩\n",
      "俳\n",
      "俾\n",
      "倓\n",
      "倞\n",
      "倡\n",
      "傍\n",
      "傻\n",
      "僭\n",
      "僴\n",
      "僾\n",
      "允\n",
      "兄\n",
      "先\n",
      "党\n",
      "六\n",
      "兼\n",
      "兽\n",
      "冬\n",
      "决\n",
      "冶\n",
      "减\n",
      "凑\n",
      "凯\n",
      "刃\n",
      "划\n",
      "剐\n",
      "办\n",
      "加\n",
      "劣\n",
      "勖\n",
      "化\n",
      "匦\n",
      "千\n",
      "卍\n",
      "卫\n",
      "厅\n",
      "厓\n",
      "厶\n",
      "及\n",
      "叧\n",
      "史\n",
      "司\n",
      "君\n",
      "吟\n",
      "听\n",
      "呃\n",
      "呔\n",
      "呙\n",
      "咀\n",
      "咋\n",
      "咛\n",
      "咟\n",
      "咩\n",
      "响\n",
      "哐\n",
      "哪\n",
      "哲\n",
      "哴\n",
      "哺\n",
      "哼\n",
      "唁\n",
      "唆\n",
      "唇\n",
      "唉\n",
      "唛\n",
      "唠\n",
      "唱\n",
      "唿\n",
      "啃\n",
      "啐\n",
      "啤\n",
      "啥\n",
      "啧\n",
      "啶\n",
      "善\n",
      "喫\n",
      "喵\n",
      "嗙\n",
      "嗟\n",
      "嗳\n",
      "嗵\n",
      "嗼\n",
      "嗾\n",
      "嘁\n",
      "嘛\n",
      "噍\n",
      "噫\n",
      "噹\n",
      "囥\n",
      "囷\n",
      "圫\n",
      "圳\n",
      "圹\n",
      "均\n",
      "坍\n",
      "坞\n",
      "坪\n",
      "坼\n",
      "垌\n",
      "垠\n",
      "埆\n",
      "埇\n",
      "埭\n",
      "堠\n",
      "堺\n",
      "塙\n",
      "填\n",
      "墅\n",
      "壵\n",
      "壶\n",
      "壻\n",
      "备\n",
      "夏\n",
      "夕\n",
      "外\n",
      "奂\n",
      "奢\n",
      "妊\n",
      "妬\n",
      "妯\n",
      "妾\n",
      "姑\n",
      "姮\n",
      "娈\n",
      "娠\n",
      "媺\n",
      "嫄\n",
      "嫋\n",
      "嫖\n",
      "嬖\n",
      "嬴\n",
      "孑\n",
      "孖\n",
      "孳\n",
      "宀\n",
      "宁\n",
      "宕\n",
      "宠\n",
      "审\n",
      "宬\n",
      "宵\n",
      "寇\n",
      "富\n",
      "寡\n",
      "尥\n",
      "尪\n",
      "尴\n",
      "尸\n",
      "层\n",
      "展\n",
      "岔\n",
      "岡\n",
      "峰\n",
      "峻\n",
      "嶒\n",
      "嶲\n",
      "嶽\n",
      "师\n",
      "帔\n",
      "幛\n",
      "并\n",
      "幺\n",
      "庵\n",
      "庼\n",
      "庾\n",
      "开\n",
      "弦\n",
      "弶\n",
      "弼\n",
      "彊\n",
      "彐\n",
      "徇\n",
      "得\n",
      "御\n",
      "徵\n",
      "忭\n",
      "忽\n",
      "急\n",
      "恋\n",
      "恤\n",
      "恧\n",
      "恻\n",
      "悬\n",
      "悭\n",
      "悯\n",
      "惋\n",
      "惟\n",
      "愈\n",
      "慄\n",
      "慝\n",
      "戏\n",
      "戛\n",
      "扁\n",
      "扇\n",
      "扌\n",
      "扣\n",
      "抑\n",
      "抬\n",
      "押\n",
      "拥\n",
      "拧\n",
      "拱\n",
      "挈\n",
      "按\n",
      "挣\n",
      "挽\n",
      "捌\n",
      "捏\n",
      "据\n",
      "掂\n",
      "掘\n",
      "掴\n",
      "揿\n",
      "搞\n",
      "摘\n",
      "撅\n",
      "撚\n",
      "撞\n",
      "攀\n",
      "攒\n",
      "攥\n",
      "放\n",
      "敝\n",
      "敞\n",
      "敦\n",
      "敫\n",
      "敬\n",
      "敷\n",
      "文\n",
      "斗\n",
      "料\n",
      "斟\n",
      "斯\n",
      "方\n",
      "於\n",
      "旁\n",
      "旒\n",
      "旗\n",
      "日\n",
      "旦\n",
      "旮\n",
      "昉\n",
      "晞\n",
      "晡\n",
      "普\n",
      "晳\n",
      "暑\n",
      "暗\n",
      "暲\n",
      "暹\n",
      "朗\n",
      "末\n",
      "朴\n",
      "朽\n",
      "杀\n",
      "杆\n",
      "杈\n",
      "村\n",
      "杠\n",
      "杮\n",
      "杵\n",
      "杼\n",
      "板\n",
      "构\n",
      "枒\n",
      "枓\n",
      "枕\n",
      "枯\n",
      "枰\n",
      "柠\n",
      "柱\n",
      "栋\n",
      "校\n",
      "栫\n",
      "案\n",
      "桢\n",
      "桦\n",
      "梧\n",
      "梿\n",
      "棕\n",
      "棹\n",
      "棺\n",
      "椑\n",
      "椽\n",
      "楠\n",
      "楮\n",
      "榅\n",
      "榫\n",
      "榴\n",
      "槜\n",
      "樋\n",
      "樟\n",
      "橑\n",
      "橞\n",
      "橼\n",
      "檐\n",
      "檩\n",
      "櫈\n",
      "次\n",
      "欢\n",
      "欧\n",
      "歃\n",
      "歙\n",
      "此\n",
      "殇\n",
      "殒\n",
      "殖\n",
      "殛\n",
      "气\n",
      "氚\n",
      "氩\n",
      "氮\n",
      "氽\n",
      "汁\n",
      "汙\n",
      "污\n",
      "汤\n",
      "汫\n",
      "汾\n",
      "沅\n",
      "沉\n",
      "沌\n",
      "沪\n",
      "沰\n",
      "河\n",
      "沸\n",
      "泓\n",
      "泠\n",
      "注\n",
      "泯\n",
      "泳\n",
      "泷\n",
      "洑\n",
      "洧\n",
      "洨\n",
      "洵\n",
      "洹\n",
      "洼\n",
      "浈\n",
      "浊\n",
      "浏\n",
      "浓\n",
      "浙\n",
      "浚\n",
      "浞\n",
      "浪\n",
      "浯\n",
      "涛\n",
      "涡\n",
      "润\n",
      "涯\n",
      "涰\n",
      "液\n",
      "涶\n",
      "淖\n",
      "淝\n",
      "淞\n",
      "淤\n",
      "淦\n",
      "淬\n",
      "淮\n",
      "淹\n",
      "渎\n",
      "渐\n",
      "渢\n",
      "渺\n",
      "湟\n",
      "湶\n",
      "湿\n",
      "源\n",
      "溥\n",
      "溴\n",
      "溹\n",
      "溻\n",
      "滆\n",
      "滘\n",
      "滞\n",
      "滥\n",
      "滦\n",
      "滪\n",
      "漉\n",
      "漏\n",
      "漯\n",
      "漱\n",
      "漶\n",
      "潄\n",
      "潋\n",
      "潼\n",
      "澍\n",
      "澎\n",
      "澥\n",
      "激\n",
      "濉\n",
      "火\n",
      "灿\n",
      "炀\n",
      "炆\n",
      "炳\n",
      "烔\n",
      "烙\n",
      "烚\n",
      "焐\n",
      "煜\n",
      "熕\n",
      "燏\n",
      "爀\n",
      "牛\n",
      "牝\n",
      "牡\n",
      "牯\n",
      "牴\n",
      "牾\n",
      "状\n",
      "狈\n",
      "狠\n",
      "狼\n",
      "猄\n",
      "猊\n",
      "玑\n",
      "玓\n",
      "玖\n",
      "玗\n",
      "玠\n",
      "玡\n",
      "玦\n",
      "玮\n",
      "玳\n",
      "珠\n",
      "珩\n",
      "珮\n",
      "琪\n",
      "琯\n",
      "琰\n",
      "瑁\n",
      "瑞\n",
      "瑠\n",
      "璆\n",
      "璐\n",
      "璜\n",
      "璟\n",
      "瓒\n",
      "瓜\n",
      "瓣\n",
      "瓦\n",
      "瓶\n",
      "画\n",
      "畁\n",
      "畜\n",
      "畸\n",
      "疥\n",
      "疫\n",
      "疬\n",
      "疱\n",
      "疲\n",
      "疴\n",
      "疸\n",
      "疽\n",
      "症\n",
      "痛\n",
      "痢\n",
      "痧\n",
      "痪\n",
      "痴\n",
      "痾\n",
      "痿\n",
      "瘗\n",
      "瘼\n",
      "瘿\n",
      "癣\n",
      "癫\n",
      "皆\n",
      "皖\n",
      "盔\n",
      "盙\n",
      "盲\n",
      "睪\n",
      "睾\n",
      "瞒\n",
      "瞟\n",
      "瞡\n",
      "矛\n",
      "知\n",
      "矻\n",
      "矾\n",
      "砀\n",
      "码\n",
      "砜\n",
      "砰\n",
      "硇\n",
      "碇\n",
      "碗\n",
      "碲\n",
      "磬\n",
      "祝\n",
      "禟\n",
      "离\n",
      "禽\n",
      "秖\n",
      "穿\n",
      "窅\n",
      "窆\n",
      "窜\n",
      "竞\n",
      "童\n",
      "笈\n",
      "笍\n",
      "笏\n",
      "笕\n",
      "筇\n",
      "筌\n",
      "筍\n",
      "筱\n",
      "筲\n",
      "箅\n",
      "箓\n",
      "篏\n",
      "篔\n",
      "篝\n",
      "簖\n",
      "籚\n",
      "籼\n",
      "粗\n",
      "粲\n",
      "糌\n",
      "累\n",
      "纸\n",
      "纽\n",
      "绊\n",
      "绗\n",
      "绚\n",
      "绹\n",
      "缉\n",
      "缽\n",
      "罅\n",
      "罚\n",
      "羁\n",
      "羹\n",
      "翫\n",
      "考\n",
      "耸\n",
      "聍\n",
      "肘\n",
      "肝\n",
      "肮\n",
      "肼\n",
      "胍\n",
      "胚\n",
      "胺\n",
      "脩\n",
      "脲\n",
      "腊\n",
      "腐\n",
      "腑\n",
      "腰\n",
      "膀\n",
      "膛\n",
      "膝\n",
      "臆\n",
      "自\n",
      "臼\n",
      "舄\n",
      "舣\n",
      "芮\n",
      "苗\n",
      "苴\n",
      "茱\n",
      "草\n",
      "荡\n",
      "莴\n",
      "菌\n",
      "萜\n",
      "萼\n",
      "葳\n",
      "葺\n",
      "蒯\n",
      "蒴\n",
      "蓦\n",
      "蕚\n",
      "蕻\n",
      "藨\n",
      "藿\n",
      "虎\n",
      "蚁\n",
      "蚪\n",
      "蚴\n",
      "蛇\n",
      "蛏\n",
      "蜊\n",
      "蜣\n",
      "蝣\n",
      "蝴\n",
      "螃\n",
      "蟑\n",
      "蟠\n",
      "蟥\n",
      "蟮\n",
      "蠡\n",
      "血\n",
      "衣\n",
      "补\n",
      "表\n",
      "衫\n",
      "袱\n",
      "裳\n",
      "褔\n",
      "褪\n",
      "褴\n",
      "襦\n",
      "角\n",
      "觥\n",
      "觫\n",
      "觳\n",
      "訾\n",
      "认\n",
      "讫\n",
      "讲\n",
      "讷\n",
      "诃\n",
      "诊\n",
      "诌\n",
      "话\n",
      "诠\n",
      "诡\n",
      "该\n",
      "诮\n",
      "诶\n",
      "诸\n",
      "诹\n",
      "读\n",
      "课\n",
      "调\n",
      "谄\n",
      "谅\n",
      "谇\n",
      "谌\n",
      "谍\n",
      "谓\n",
      "谧\n",
      "谮\n",
      "谲\n",
      "豹\n",
      "豺\n",
      "贬\n",
      "贮\n",
      "贿\n",
      "赅\n",
      "赌\n",
      "赐\n",
      "赒\n",
      "赛\n",
      "赢\n",
      "越\n",
      "趼\n",
      "跄\n",
      "跪\n",
      "跸\n",
      "跹\n",
      "踺\n",
      "蹓\n",
      "躂\n",
      "躍\n",
      "躭\n",
      "輶\n",
      "车\n",
      "轪\n",
      "轭\n",
      "辟\n",
      "辰\n",
      "迅\n",
      "迎\n",
      "迕\n",
      "违\n",
      "迪\n",
      "述\n",
      "迳\n",
      "迹\n",
      "逃\n",
      "逋\n",
      "透\n",
      "逑\n",
      "通\n",
      "速\n",
      "逼\n",
      "遄\n",
      "遆\n",
      "遇\n",
      "遊\n",
      "遨\n",
      "邂\n",
      "邓\n",
      "邛\n",
      "邦\n",
      "邨\n",
      "邹\n",
      "邺\n",
      "邽\n",
      "郞\n",
      "郫\n",
      "郭\n",
      "鄨\n",
      "酥\n",
      "酾\n",
      "醍\n",
      "醢\n",
      "銮\n",
      "鋐\n",
      "錝\n",
      "錤\n",
      "鍊\n",
      "鏖\n",
      "钊\n",
      "钍\n",
      "钒\n",
      "钖\n",
      "钙\n",
      "钟\n",
      "钠\n",
      "钣\n",
      "钥\n",
      "钨\n",
      "钪\n",
      "钮\n",
      "钶\n",
      "钸\n",
      "钺\n",
      "铈\n",
      "铎\n",
      "铜\n",
      "铥\n",
      "铮\n",
      "铵\n",
      "铿\n",
      "锂\n",
      "锗\n",
      "锤\n",
      "键\n",
      "锲\n",
      "锶\n",
      "锺\n",
      "锿\n",
      "镂\n",
      "镊\n",
      "镎\n",
      "镠\n",
      "镨\n",
      "镫\n",
      "长\n",
      "闸\n",
      "闾\n",
      "阆\n",
      "阐\n",
      "阝\n",
      "际\n",
      "陈\n",
      "陋\n",
      "除\n",
      "陧\n",
      "隄\n",
      "隅\n",
      "难\n",
      "雎\n",
      "雨\n",
      "霾\n",
      "靝\n",
      "靡\n",
      "靭\n",
      "靶\n",
      "韁\n",
      "韮\n",
      "顼\n",
      "顽\n",
      "顿\n",
      "颁\n",
      "颂\n",
      "颊\n",
      "颌\n",
      "飈\n",
      "飐\n",
      "飕\n",
      "飘\n",
      "饀\n",
      "饥\n",
      "饨\n",
      "饷\n",
      "饸\n",
      "馄\n",
      "馏\n",
      "驯\n",
      "驺\n",
      "骇\n",
      "验\n",
      "骝\n",
      "魄\n",
      "鮰\n",
      "鰼\n",
      "鲅\n",
      "鲊\n",
      "鲏\n",
      "鲵\n",
      "鲷\n",
      "鲽\n",
      "鳃\n",
      "鳖\n",
      "鳘\n",
      "鳥\n",
      "鶵\n",
      "鸉\n",
      "鸡\n",
      "鸥\n",
      "鹀\n",
      "鹑\n",
      "鹫\n",
      "鹮\n",
      "鹰\n",
      "鹳\n",
      "麒\n",
      "黹\n",
      "鼍\n",
      "鼹\n",
      "龆\n",
      "龌\n"
     ]
    }
   ],
   "source": [
    "for indece in indeces:\n",
    "    print(Y_data[indece])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d50ed946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(X_data[indeces[0]])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4833ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageChops\n",
    "import math, operator\n",
    "from functools import reduce\n",
    "def rmsdiff(im1, im2):\n",
    "    \"Calculate the root-mean-square difference between two images\"\n",
    "\n",
    "    h = ImageChops.difference(im1, im2).histogram()\n",
    "\n",
    "    # calculate rms\n",
    "    return math.sqrt(reduce(operator.add,\n",
    "        map(lambda h, i: h*(i**2), h, range(256))\n",
    "    ) / (float(im1.size[0]) * im1.size[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05e36bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "path_to_fonts = 'img'\n",
    "X_data_test = []\n",
    "for root, dirs, files in os.walk(path_to_fonts): \n",
    "    for file in files: \n",
    "        for font in filelist:\n",
    "            if(font in file and '30' in file):\n",
    "                X_data_test.append(Image.open(os.path.join(root,file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c501e573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в кластере 0 растояние между 861 иероглифами 24627619.49802934\n",
      "в кластере 1 растояние между 1102 иероглифами 40639439.71401044\n",
      "в кластере 2 растояние между 1084 иероглифами 39189947.584733464\n",
      "в кластере 3 растояние между 727 иероглифами 17687748.83316873\n",
      "в кластере 4 растояние между 1158 иероглифами 44840363.84596485\n",
      "в кластере 5 растояние между 181 иероглифами 1070779.3530345864\n",
      "в кластере 6 растояние между 1000 иероглифами 33412821.21187805\n",
      "в кластере 7 растояние между 587 иероглифами 11393443.470595779\n",
      "в кластере 8 растояние между 217 иероглифами 1563420.8836128975\n",
      "в кластере 9 растояние между 1267 иероглифами 53647320.011301145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "#summ = 0\n",
    "for lable in range(10):\n",
    "    indeces = get_indices(kmeans.labels_, lable)\n",
    "    summ_ind = 0\n",
    "    for i in range(len(indeces)):\n",
    "        for j in range(i+1, len(indeces)):\n",
    "            summ_ind = summ_ind + rmsdiff(X_data_test[indeces[i]], X_data_test[indeces[j]])\n",
    "    print(\"в кластере \" + str(lable) + \" растояние между \" + str(len(indeces)) + \" иероглифами \" + str(summ_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9c82f9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в кластере 0 растояние между 819 иероглифами 22391789.93753253\n",
      "в кластере 1 растояние между 819 иероглифами 22362396.81822122\n",
      "в кластере 2 растояние между 819 иероглифами 22326186.68747913\n",
      "в кластере 3 растояние между 819 иероглифами 22398292.900058318\n",
      "в кластере 4 растояние между 818 иероглифами 22307560.89963723\n",
      "в кластере 5 растояние между 818 иероглифами 22305920.60040963\n",
      "в кластере 6 растояние между 818 иероглифами 22323229.93200398\n",
      "в кластере 7 растояние между 818 иероглифами 22341806.37930896\n",
      "в кластере 8 растояние между 818 иероглифами 22375296.133906554\n",
      "в кластере 9 растояние между 818 иероглифами 22375995.477952268\n"
     ]
    }
   ],
   "source": [
    "#summ = 0\n",
    "lable = 0\n",
    "from sklearn import utils\n",
    "for X_array in np.array_split(utils.shuffle(X_data_test), 10):\n",
    "    rms_lable = 0\n",
    "   # print(\"идет работа с кластером \" + str(lable) + \" \" + str(summ))\n",
    "    #summ_ind = 0\n",
    "    for i in range(len(X_array)):\n",
    "        for j in range(i+1,len(X_array)):\n",
    "            rms_lable = rms_lable + rmsdiff(X_array[i], X_array[j])\n",
    "    print(\"в кластере \" + str(lable) + \" растояние между \" + str(len(X_array)) + \" иероглифами \" + str(rms_lable))\n",
    "    lable = lable + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
